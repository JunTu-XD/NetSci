{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "### Singe Random Network\n",
    "### network config\n",
    "AVG_DEGREE = 6\n",
    "NUM_NODE = 200\n",
    "GIANT_COMPONENT_THRESHOLD=0.90\n",
    "NUM_ITER=100\n",
    "PROTECT_HUB_DEGREE = 999999999\n",
    "FILE=\"output.txt\"\n",
    "PROTECT_BETWEENNESS=0\n",
    "\n",
    "ATTR_LAYER = \"layer\"\n",
    "LAYER_A_TAG = \"L_A\"\n",
    "LAYER_B_TAG = \"L_B\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "layer_a=[]\n",
    "layer_b=[]\n",
    "interconnect_stg=[]\n",
    "attack_stg=[]\n",
    "### Test\n",
    "# layer_a+=[\"ER\"]\n",
    "# layer_b+=[\"ER\"]\n",
    "# interconnect_stg+=[\"Max_min_d\"]\n",
    "# attack_stg+=[\"Max_d\"]\n",
    "\n",
    "# ER-ER BA-BA random attack\n",
    "# layer_a+=[\"ER\"]*3\n",
    "# layer_b+=[\"ER\"]*3\n",
    "# interconnect_stg+=[\"Random\", \"Max_min_d\", \"Max_max_d\"]\n",
    "# attack_stg+=[\"Random\"]*3\n",
    "# layer_a+=[\"BA\"]*3\n",
    "# layer_b+=[\"BA\"]*3\n",
    "# interconnect_stg+=[\"Random\",\"Max_min_d\", \"Max_max_d\"]\n",
    "# attack_stg+=[\"Random\"]*3\n",
    "#\n",
    "# #ER-ER BA-BA high_d target_atk\n",
    "# layer_a+=[\"ER\"]*2\n",
    "# layer_b+=[\"ER\"]*2\n",
    "# interconnect_stg+=[\"Max_max_d\"]*2\n",
    "# attack_stg+=[\"Max_d\",\"Min_d\"]\n",
    "#\n",
    "# layer_a+=[\"BA\"]*2\n",
    "# layer_b+=[\"BA\"]*2\n",
    "# interconnect_stg+=[\"Max_max_d\"]*2\n",
    "# attack_stg+=[\"Max_d\",\"Min_d\"]\n",
    "#\n",
    "# # ER-BA BA-ER HH/R HDA/RA\n",
    "# layer_a+=[\"ER\",\"ER\",\"ER\",\"ER\",\"BA\",\"BA\",\"BA\",\"BA\"]\n",
    "# layer_b+=[\"BA\",\"BA\",\"BA\",\"BA\",\"ER\",\"ER\",\"ER\",\"ER\"]\n",
    "# interconnect_stg+=[\"Random\",\"Random\",\"Max_max_d\",\"Max_max_d\",\"Random\",\"Random\",\"Max_max_d\",\"Max_max_d\"]\n",
    "# attack_stg+=      [\"Max_d\",  \"Random\",\"Max_d\",   \"Random\",   \"Max_d\", \"Random\",  \"Max_d\",   \"Random\"]\n",
    "#\n",
    "# #ER-ER BA-BA HBA\n",
    "# layer_a+=[\"ER\",\"ER\",\"ER\",\"BA\",\"BA\",\"BA\"]\n",
    "# layer_b+=[\"ER\",\"ER\",\"ER\",\"BA\",\"BA\",\"BA\"]\n",
    "# interconnect_stg+=[\"Random\"]*6\n",
    "# attack_stg+=[\"Max_d\",\"Random\",\"Max_b\"]*2\n",
    "#\n",
    "# #ER-ER R LDA/RA\n",
    "# layer_a+=[\"ER\",\"ER\"]\n",
    "# layer_b+=[\"ER\",\"ER\"]\n",
    "# interconnect_stg+=[\"Random\"]*2\n",
    "# attack_stg+=[\"Min_d\",\"Random\"]\n",
    "#\n",
    "\n",
    "\n",
    "# layer_a+=[\"ER\",\"ER\"]\n",
    "# layer_b+=[\"ER\",\"ER\"]\n",
    "# PROTECT_HUB_DEGREE = 12\n",
    "# interconnect_stg+=[\"Max_max_d\"]*2\n",
    "# attack_stg+=[\"Max_d\",\"Random\"]\n",
    "# FILE_TAG=\"Prot_\"\n",
    "# layer_a+=[\"BA\",\"BA\"]\n",
    "# layer_b+=[\"BA\",\"BA\"]\n",
    "# PROTECT_HUB_DEGREE = 31\n",
    "# interconnect_stg+=[\"Max_max_d\"]*2\n",
    "# attack_stg+=[\"Max_d\",\"Random\"]\n",
    "# FILE_TAG=\"Prot_\"\n",
    "##\n",
    "\n",
    "#### need to treat the output separetely\n",
    "layer_a+=[\"BA\",\"BA\", \"ER\",\"ER\"]\n",
    "layer_b+=[\"BA\",\"BA\", \"ER\", \"ER\"]\n",
    "interconnect_stg+=[\"Max_max_d\"]*4\n",
    "attack_stg+=[\"Max_d\",\"Random\"]*2\n",
    "FILE_TAG=\"Prot_HB_\"\n",
    "PROTECT_BETWEENNESS=0.02\n",
    "###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig_idx = 0\n",
    "def new_fig():\n",
    "    global fig_idx\n",
    "    plt.figure(fig_idx)\n",
    "    fig_idx += 1\n",
    "\n",
    "def sort_max_degree(G):\n",
    "    degree = dict(nx.degree(G))\n",
    "    return max(degree, key=degree.get)\n",
    "\n",
    "def sort_degree_desc(G):\n",
    "    degree = dict(nx.degree(G))\n",
    "    return {k: v for k, v in sorted(degree.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "def sort_degree_asc(G):\n",
    "    degree = dict(nx.degree(G))\n",
    "    return {k: v for k, v in sorted(degree.items(), key=lambda item: item[1], reverse=False)}\n",
    "\n",
    "def sort_clustering_coefficient_desc(G):\n",
    "    clustering_coefficient = dict(nx.clustering(G))\n",
    "    return {k: v for k, v in sorted(clustering_coefficient.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "def sort_clustering_coefficient_asc(G):\n",
    "    clustering_coefficient = dict(nx.clustering(G))\n",
    "    return {k: v for k, v in sorted(clustering_coefficient.items(), key=lambda item: item[1], reverse=False)}\n",
    "\n",
    "def sort_betweenness_centrality_desc(G):\n",
    "    betweenness_centrality = dict(nx.betweenness_centrality(G))\n",
    "    return {k: v for k, v in sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "def sort_betweenness_centrality_asc(G):\n",
    "    betweenness_centrality = dict(nx.betweenness_centrality(G))\n",
    "    return {k: v for k, v in sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=False)}\n",
    "\n",
    "def draw_interdependent_G(G):\n",
    "    global ATTR_LAYER, LAYER_A_TAG, LAYER_B_TAG\n",
    "    layer_attr=nx.get_node_attributes(G,ATTR_LAYER)\n",
    "    color_map = ['b' if layer_attr[node][0]== LAYER_A_TAG else 'g' for node in list(G.nodes())]\n",
    "    new_fig()\n",
    "    nx.draw(G, node_color=color_map, node_size=30)\n",
    "\n",
    "### with certain average degree\n",
    "##### ER\n",
    "def generate_ER(avg_degree):\n",
    "    global NUM_NODE\n",
    "    p = np.true_divide(avg_degree, NUM_NODE)\n",
    "    return nx.erdos_renyi_graph(NUM_NODE, p)\n",
    "#### BA\n",
    "def generate_BA(avg_degree):\n",
    "    global NUM_NODE\n",
    "    return nx.random_graphs.barabasi_albert_graph(NUM_NODE, round(avg_degree/2))\n",
    "\n",
    "### inter-connect\n",
    "### add properties of whether nodes is Layer A or B for further use\n",
    "### return: G\n",
    "####\n",
    "#### e.g. max_max means nodes in layer A with highest degree centralities\n",
    "####         connect to  nodes in layer A with highest degree centralities\n",
    "def interconnect(G_layer_A, L_A, G_layer_B, L_B):\n",
    "    G = nx.union(G_layer_A, G_layer_B)\n",
    "    layer_mapping = dict()\n",
    "    for idx in range(len(L_A.items())):\n",
    "        node_A = list(L_A.keys())[idx]\n",
    "        node_B = list(L_B.keys())[idx]\n",
    "        layer_mapping.update(dict({node_A:node_B}))\n",
    "        G.add_edge(node_A, node_B)\n",
    "    return G, layer_mapping\n",
    "\n",
    "def interconnect_random(G_layer_A, G_layer_B):\n",
    "    shuffle = np.random.permutation(NUM_NODE)\n",
    "    G_layer_A_nodes = list(G_layer_A.nodes())\n",
    "    G_layer_A_nodes = np.asarray(G_layer_A_nodes)[shuffle]\n",
    "    G_layer_A_nodes = {n:1 for n in G_layer_A_nodes }\n",
    "    G_layer_B_nodes = dict(G_layer_B.nodes())\n",
    "    return interconnect(G_layer_A, G_layer_A_nodes, G_layer_B, G_layer_B_nodes)\n",
    "\n",
    "\n",
    "def interconnect_max_max_degree_centralities(G_layer_A, G_layer_B):\n",
    "    L_A_degree_centrality = sort_degree_desc(G_layer_A)\n",
    "    L_B_degree_centrality = sort_degree_desc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_degree_centrality, G_layer_B, L_B_degree_centrality)\n",
    "def interconnect_max_min_degree_centralities(G_layer_A, G_layer_B):\n",
    "    L_A_degree_centrality = sort_degree_desc(G_layer_A)\n",
    "    L_B_degree_centrality = sort_degree_asc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_degree_centrality, G_layer_B, L_B_degree_centrality)\n",
    "def interconnect_min_max_degree_centralities(G_layer_A, G_layer_B):\n",
    "    L_A_degree_centrality = sort_degree_asc(G_layer_A)\n",
    "    L_B_degree_centrality = sort_degree_desc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_degree_centrality, G_layer_B, L_B_degree_centrality)\n",
    "def interconnect_min_min_degree_centralities(G_layer_A, G_layer_B):\n",
    "    L_A_degree_centrality = sort_degree_asc(G_layer_A)\n",
    "    L_B_degree_centrality = sort_degree_asc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_degree_centrality, G_layer_B, L_B_degree_centrality)\n",
    "\n",
    "def interconnect_max_max_clustering(G_layer_A, G_layer_B):\n",
    "    L_A_clustering_coefficient = sort_clustering_coefficient_desc(G_layer_A)\n",
    "    L_B_clustering_coefficient = sort_clustering_coefficient_desc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_clustering_coefficient, G_layer_B, L_B_clustering_coefficient)\n",
    "def interconnect_min_max_clustering(G_layer_A, G_layer_B):\n",
    "    L_A_clustering_coefficient = sort_clustering_coefficient_asc(G_layer_A)\n",
    "    L_B_clustering_coefficient = sort_clustering_coefficient_desc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_clustering_coefficient, G_layer_B, L_B_clustering_coefficient)\n",
    "def interconnect_max_min_clustering(G_layer_A, G_layer_B):\n",
    "    L_A_clustering_coefficient = sort_clustering_coefficient_desc(G_layer_A)\n",
    "    L_B_clustering_coefficient = sort_clustering_coefficient_asc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_clustering_coefficient, G_layer_B, L_B_clustering_coefficient)\n",
    "def interconnect_min_min_clustering(G_layer_A, G_layer_B):\n",
    "    L_A_clustering_coefficient = sort_clustering_coefficient_asc(G_layer_A)\n",
    "    L_B_clustering_coefficient = sort_clustering_coefficient_asc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_clustering_coefficient, G_layer_B, L_B_clustering_coefficient)\n",
    "\n",
    "\n",
    "def interconnect_max_max_betweeness(G_layer_A, G_layer_B):\n",
    "    L_A_betweenness_centrality = sort_betweenness_centrality_desc(G_layer_A)\n",
    "    L_B_betweenness_centrality = sort_betweenness_centrality_desc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_betweenness_centrality, G_layer_B, L_B_betweenness_centrality)\n",
    "def interconnect_max_min_betweeness(G_layer_A, G_layer_B):\n",
    "    L_A_betweenness_centrality = sort_betweenness_centrality_desc(G_layer_A)\n",
    "    L_B_betweenness_centrality = sort_betweenness_centrality_asc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_betweenness_centrality, G_layer_B, L_B_betweenness_centrality)\n",
    "def interconnect_min_max_betweeness(G_layer_A, G_layer_B):\n",
    "    L_A_betweenness_centrality = sort_betweenness_centrality_asc(G_layer_A)\n",
    "    L_B_betweenness_centrality = sort_betweenness_centrality_desc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_betweenness_centrality, G_layer_B, L_B_betweenness_centrality)\n",
    "def interconnect_min_min_betweeness(G_layer_A, G_layer_B):\n",
    "    L_A_betweenness_centrality = sort_betweenness_centrality_asc(G_layer_A)\n",
    "    L_B_betweenness_centrality = sort_betweenness_centrality_asc(G_layer_B)\n",
    "    return interconnect(G_layer_A, L_A_betweenness_centrality, G_layer_B, L_B_betweenness_centrality)\n",
    "\n",
    "#### simulation\n",
    "def simulate(interdependent_G:nx.Graph, L_A:nx.Graph, L_B:nx.Graph, layer_mapping, attack_nodes:[]):\n",
    "    global M_MONTE_CARLO, NODE_DESTROY_THRESHOLD, LAYER_A_TAG, LAYER_B_TAG, PROTECT_HUB_DEGREE, PROTECT_BETWEENNESS\n",
    "    G = interdependent_G.copy()\n",
    "    ### it can be reformate better\n",
    "    protected_nodes_A = []\n",
    "    for n in L_A.nodes():\n",
    "        if L_A.degree()[n] >= PROTECT_HUB_DEGREE :\n",
    "            protected_nodes_A.append(n)\n",
    "    protected_nodes_B = []\n",
    "    for n in L_B.nodes():\n",
    "        if L_B.degree()[n] > PROTECT_HUB_DEGREE :\n",
    "            protected_nodes_B.append(n)\n",
    "    if (PROTECT_BETWEENNESS >0 ):\n",
    "        protect_nodes_num = round(len(interdependent_G.nodes())*PROTECT_BETWEENNESS)\n",
    "        h_betweeness = sort_betweenness_centrality_desc(interdependent_G)\n",
    "        protected_nodes = [t[0] for t in list(h_betweeness.items())[:protect_nodes_num]]\n",
    "        for pn in protected_nodes:\n",
    "            if  LAYER_A_TAG in pn:\n",
    "                protected_nodes_A.append(pn)\n",
    "            if LAYER_B_TAG in pn:\n",
    "                protected_nodes_B.append(pn)\n",
    "\n",
    "    attack_nodes_after_protect=[]\n",
    "    for atk_n in attack_nodes:\n",
    "        if (atk_n not in protected_nodes_A) and (atk_n not in protected_nodes_B):\n",
    "            attack_nodes_after_protect.append(atk_n)\n",
    "\n",
    "    G.remove_nodes_from(attack_nodes_after_protect)\n",
    "    ## remove nodes in A and B\n",
    "    L_A.remove_nodes_from(attack_nodes_after_protect)\n",
    "    L_B.remove_nodes_from(attack_nodes_after_protect)\n",
    "    for node in attack_nodes_after_protect:\n",
    "        L_B.remove_node(layer_mapping[node])\n",
    "        G.remove_node(layer_mapping[node])\n",
    "    layer_mapping_B_to_A = {v: k for k, v in layer_mapping.items()}\n",
    "    while True:\n",
    "        L_A_ends=True\n",
    "        L_B_ends = True\n",
    "        ## find cluster in A\n",
    "        clusters_A = list(nx.connected_components(L_A))\n",
    "        ### for cluster A_i\n",
    "        for c_A in clusters_A:\n",
    "            c_A_to_B = [layer_mapping[n_A] for n_A in c_A]\n",
    "            for n_B in c_A_to_B:\n",
    "                edges =  L_B.edges(n_B)\n",
    "                remove_edges = []\n",
    "                for edge in edges:\n",
    "                    if (edge[0] not in c_A_to_B) or (edge[1] not in c_A_to_B):\n",
    "                        remove_edges.append(edge)\n",
    "                if len(remove_edges)>0:\n",
    "                    G.remove_edges_from(remove_edges)\n",
    "                    L_B.remove_edges_from(remove_edges)\n",
    "                    L_A_ends=False\n",
    "        ## find cluster in B\n",
    "        clusters_B = list(nx.connected_components(L_B))\n",
    "        for c_B in clusters_B:\n",
    "            c_B_to_A = [layer_mapping_B_to_A[n_B] for n_B in c_B]\n",
    "            for n_A in c_B_to_A:\n",
    "                edges =  L_A.edges(n_A)\n",
    "                remove_edges = []\n",
    "                for edge in edges:\n",
    "                    if (edge[0] not in c_B_to_A) or (edge[1] not in c_B_to_A):\n",
    "                        remove_edges.append(edge)\n",
    "                if len(remove_edges)>0:\n",
    "                    G.remove_edges_from(remove_edges)\n",
    "                    L_A.remove_edges_from(remove_edges)\n",
    "                    L_B_ends=False\n",
    "        if (L_A_ends and L_B_ends) :\n",
    "            break\n",
    "    return measurement(G)\n",
    "\n",
    "\n",
    "#### measurement\n",
    "def measurement(G):\n",
    "    global NUM_NODE, GIANT_COMPONENT_THRESHOLD\n",
    "    ## measurement\n",
    "    giant_component_exist = 1\n",
    "    #### largest component size / G size\n",
    "    miu = 0.0\n",
    "    G_nodes_num = len(G.nodes())\n",
    "    sub_components = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    G_0_size = len(sub_components[0])\n",
    "    if (G_0_size/G_nodes_num <  GIANT_COMPONENT_THRESHOLD):\n",
    "        giant_component_exist = 0\n",
    "\n",
    "    miu = np.true_divide(G_0_size, G_nodes_num)\n",
    "\n",
    "    ###\n",
    "    ret = giant_component_exist, miu\n",
    "    return ret\n",
    "\n",
    "\n",
    "#### attack nodes\n",
    "def attack_random_Layer_A(G_A, p):\n",
    "    global NUM_NODE\n",
    "    attack_num = round(NUM_NODE * p)\n",
    "    shuffler = np.random.permutation(NUM_NODE)\n",
    "    return np.asarray(G_A.nodes())[shuffler[:attack_num]]\n",
    "def attack_high_degree_Layer_A(G_A, P):\n",
    "    global  LAYER_A_TAG\n",
    "\n",
    "    A_copy = nx.Graph(G_A)\n",
    "    num = round(P*len(G_A.nodes()))\n",
    "    atk = []\n",
    "    for i in range(num):\n",
    "        atk_n = sort_max_degree(A_copy)\n",
    "        atk.append(atk_n)\n",
    "        A_copy.remove_node(atk_n)\n",
    "    return  atk\n",
    "\n",
    "def attack_high_betweenness_Layer_A(G_A, P):\n",
    "    global  LAYER_A_TAG\n",
    "    degree_c = sort_betweenness_centrality_desc(G_A)\n",
    "    num = round(P*len(G_A.nodes()))\n",
    "    return  [t[0] for t in list(degree_c.items())[:num]]\n",
    "\n",
    "def attack_low_degree_Layer_A(G_A, P):\n",
    "    global  LAYER_A_TAG\n",
    "    degree_c = sort_degree_asc(G_A)\n",
    "    num = round(P*len(G_A.nodes()))\n",
    "    return  [t[0] for t in list(degree_c.items())[:num]]\n",
    "\n",
    "def set_Layer_tag(G:nx.Graph, tag):\n",
    "    G = nx.relabel_nodes(G, lambda i: tag+\"_\"+str(i))\n",
    "\n",
    "    labels = [tag]\n",
    "    global ATTR_LAYER\n",
    "    nx.set_node_attributes(G, labels, ATTR_LAYER)\n",
    "    return G\n",
    "def draw_plot(x, measurement_ret, title):\n",
    "    global FILE_TAG,FILE\n",
    "    f = open(FILE,'a')\n",
    "    print(\"## \"+FILE_TAG, file=f)\n",
    "    for idx in range(np.asarray(measurement_ret).shape[1]):\n",
    "        new_fig()\n",
    "        plt.title(title[idx])\n",
    "        plt.plot(x, np.asarray(measurement_ret)[:, idx])\n",
    "        print(\"#\"+ title[idx], file=f)\n",
    "        print(\"x=\"+str(x), file=f)\n",
    "        print(FILE_TAG+title[idx]+\"=\"+str(list(np.asarray(measurement_ret)[:, idx])), file=f)\n",
    "    f.close()\n",
    "    pass\n",
    "##### experiment: Failure cascade\n",
    "def experiment(layer_A_function, layer_B_function, interconnect_function, attack_strategy):\n",
    "    global AVG_DEGREE,NUM_ITER\n",
    "    num_iter = NUM_ITER\n",
    "    ret_p = []\n",
    "    x_p = []\n",
    "    for p in np.arange(0.01, 1, 0.01):\n",
    "        x_p.append(p)\n",
    "        iter_ret=[]\n",
    "        for i in range(num_iter):\n",
    "            # Build interdependent networks\n",
    "            ### construct Layer A\n",
    "            G_A = layer_A_function(AVG_DEGREE)\n",
    "            G_A = set_Layer_tag(G_A, LAYER_A_TAG)\n",
    "            ### construct Layer B\n",
    "            G_B = layer_B_function(AVG_DEGREE)\n",
    "            G_B = set_Layer_tag(G_B, LAYER_B_TAG)\n",
    "\n",
    "            ### interconnect\n",
    "            G,layer_mapping = interconnect_function(G_A, G_B)\n",
    "\n",
    "            # select nodes to attack\n",
    "            attack_nodes = attack_strategy(G_A,(1-p))\n",
    "\n",
    "            # simulate cascade\n",
    "            iter_ret.append(np.asarray(simulate(G, G_A, G_B, layer_mapping, attack_nodes)))\n",
    "        ret_p.append(np.mean(iter_ret, axis=0))\n",
    "    draw_plot(x_p, ret_p, ['p_of_giant_mutual_connected_component_existing', 'largest_cluster_size_against_whole_networkk'])\n",
    "\n",
    "layer_generate={\"ER\":lambda avg_d:generate_ER(avg_d), \"BA\":lambda avg_d:generate_BA(avg_d)}\n",
    "\n",
    "\n",
    "interconnect_generate = {\"Random\":lambda G_A,G_B: interconnect_random(G_A, G_B),\\\n",
    "                         \"Max_max_d\": lambda  G_A,G_B:interconnect_max_max_degree_centralities(G_A,G_B),\\\n",
    "                         \"Max_min_d\": lambda G_A,G_B:interconnect_max_min_degree_centralities(G_A,G_B),\\\n",
    "                         \"Min_max_d\": lambda G_A,G_B:interconnect_min_max_degree_centralities(G_A,G_B),\\\n",
    "                         \"Min_min_d\": lambda G_A, G_B:interconnect_min_min_degree_centralities(G_A, G_B),\n",
    "                         \\\n",
    "                         \"Max_max_b\": lambda  G_A,G_B:interconnect_max_max_betweeness(G_A,G_B),\n",
    "                         \"Max_min_b\": lambda G_A,G_B:interconnect_max_min_betweeness(G_A,G_B),\n",
    "                         \"Min_max_b\": lambda G_A,G_B:interconnect_min_max_betweeness(G_A,G_B),\n",
    "                         \"Min_min_b\": lambda G_A, G_B:interconnect_min_min_betweeness(G_A, G_B),\n",
    "                         }\n",
    "\n",
    "attack_generate={\"Random\":lambda G,P: attack_random_Layer_A(G, P),\\\n",
    "                 \"Max_d\":lambda G,P: attack_high_degree_Layer_A(G, P),\\\n",
    "                 \"Min_d\": lambda G,P: attack_low_degree_Layer_A(G, P),\\\n",
    "                 \"Max_b\": lambda G,P: attack_high_betweenness_Layer_A(G, P)}\n",
    "\n",
    "for idx in range(len(layer_a)):\n",
    "    FILE_TAG = FILE_TAG + layer_a[idx] + \"_\" + layer_b[idx] +\"_\" + interconnect_stg[idx] + \"_Con_\"+ attack_stg[idx]+\"_ATK\"\n",
    "    experiment(layer_generate[layer_a[idx]],layer_generate[layer_b[idx]],\n",
    "           interconnect_generate[interconnect_stg[idx]],\n",
    "           attack_generate[attack_stg[idx]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}